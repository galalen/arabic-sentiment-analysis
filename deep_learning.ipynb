{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "LabeledSentence = gensim.models.doc2vec.LabeledSentence \n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tokenizer = TweetTokenizer()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleaned_data.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing: clear and clean the data from nonsense letters and words\n",
    "\n",
    "import re\n",
    "\n",
    "lst= ['#','%','@','*', ':']\n",
    "pat1 = r'@[A-Za-z0-9]+'\n",
    "\n",
    "def tokenize(tweet):\n",
    "    num = re.compile(r'[0-9]+')\n",
    "    tweet = re.sub(num, \"\", str(tweet))\n",
    "    tokens = tokenizer.tokenize(str(tweet))\n",
    "    for i in lst:\n",
    "        if i in tokens:\n",
    "            tokens.remove(i)\n",
    "    return tokens\n",
    "                                \n",
    "df['tokens'] = df['text'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>RT : خالد السليمان : لـ # ولي_العهد الأمير # م...</td>\n",
       "      <td>0</td>\n",
       "      <td>[RT, خالد, السليمان, :, لـ, ولي_العهد, الأمير,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>RT : المختصر .. العمل في الشأن الثقافي ليس فقط...</td>\n",
       "      <td>0</td>\n",
       "      <td>[RT, المختصر, .., العمل, في, الشأن, الثقافي, ل...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td># الإسكان تطلق منصة جديدة يمكنك من خلالها الحص...</td>\n",
       "      <td>2</td>\n",
       "      <td>[الإسكان, تطلق, منصة, جديدة, يمكنك, من, خلالها...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td># وزير_المالية : تم تخصيص 70 ألف أرض سكنية وتخ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[وزير_المالية, تم, تخصيص, ألف, أرض, سكنية, وتخ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>تملك السعودين للمنازل يقفز 50 % والتصاعد مستمر...</td>\n",
       "      <td>2</td>\n",
       "      <td>[تملك, السعودين, للمنازل, يقفز, والتصاعد, مستم...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  label  \\\n",
       "0           0  RT : خالد السليمان : لـ # ولي_العهد الأمير # م...      0   \n",
       "1           1  RT : المختصر .. العمل في الشأن الثقافي ليس فقط...      0   \n",
       "2           2  # الإسكان تطلق منصة جديدة يمكنك من خلالها الحص...      2   \n",
       "3           3  # وزير_المالية : تم تخصيص 70 ألف أرض سكنية وتخ...      2   \n",
       "4           4  تملك السعودين للمنازل يقفز 50 % والتصاعد مستمر...      2   \n",
       "\n",
       "                                              tokens  \n",
       "0  [RT, خالد, السليمان, :, لـ, ولي_العهد, الأمير,...  \n",
       "1  [RT, المختصر, .., العمل, في, الشأن, الثقافي, ل...  \n",
       "2  [الإسكان, تطلق, منصة, جديدة, يمكنك, من, خلالها...  \n",
       "3  [وزير_المالية, تم, تخصيص, ألف, أرض, سكنية, وتخ...  \n",
       "4  [تملك, السعودين, للمنازل, يقفز, والتصاعد, مستم...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data segmentation, \n",
    "X_train, X_test, y_train, y_test = train_test_split(df['tokens'], df['label'], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RT',\n",
       " 'خالد',\n",
       " 'السليمان',\n",
       " ':',\n",
       " 'لـ',\n",
       " 'ولي_العهد',\n",
       " 'الأمير',\n",
       " '#',\n",
       " 'محمد_بن_سلمان',\n",
       " 'الدور',\n",
       " 'الأبرز',\n",
       " 'في',\n",
       " 'أرتفاع',\n",
       " 'نسبة',\n",
       " 'التملك',\n",
       " 'لـ',\n",
       " '٥٠',\n",
       " '٪',\n",
       " 'بعد',\n",
       " 'ما',\n",
       " 'كانت',\n",
       " 'شبه',\n",
       " 'ثابته',\n",
       " 'عند',\n",
       " '٤٧',\n",
       " '٪',\n",
       " 'ك',\n",
       " '…']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the trained Word2Vec model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = Word2Vec.load('cbow.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mgalalen/.local/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('ولي', 0.9438014030456543),\n",
       " ('عهده', 0.8968819975852966),\n",
       " ('عهدنا', 0.88190758228302),\n",
       " ('عهد', 0.8595527410507202),\n",
       " ('الامير', 0.8186361193656921),\n",
       " ('سيدي', 0.8035902976989746),\n",
       " ('لولي', 0.794856071472168),\n",
       " ('خادم', 0.7939093112945557),\n",
       " ('الشاب', 0.7750820517539978),\n",
       " ('حكم', 0.768715500831604)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test word and sees it similarity\n",
    "w2v.most_similar('العهد')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mgalalen/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "pretrained_weights = w2v.wv.syn0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size, emdedding_size = pretrained_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2idx(word):\n",
    "    return w2v.wv.vocab[word].index\n",
    "\n",
    "def idx2word(idx):\n",
    "    return w2v.wv.index2word[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tf-idf matrix ...\n",
      "vocab size : 4476\n"
     ]
    }
   ],
   "source": [
    "# To find importance of the word with respect to the corpus.\n",
    "# see: http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "\n",
    "print('building tf-idf matrix ...')\n",
    "vectorizer = TfidfVectorizer(analyzer=lambda x: x, min_df=10)\n",
    "matrix = vectorizer.fit_transform([x for x in X_train])\n",
    "tfidf = dict(zip(vectorizer.get_feature_names(), vectorizer.idf_))\n",
    "print('vocab size :', len(tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert tokens to vector of words\n",
    "\n",
    "def buildWordVector(tokens, size):\n",
    "    vec = np.zeros(size).reshape((1, size))\n",
    "    count = 0.\n",
    "    for word in tokens:\n",
    "        try:\n",
    "            vec += w2v[word].reshape((1, size)) * tfidf[word]\n",
    "            count += 1.\n",
    "        except KeyError: # handling the case where the token is not\n",
    "            continue\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/mgalalen/.local/lib/python3.6/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n",
      "21482it [00:05, 3941.56it/s]\n",
      "10581it [00:02, 4308.13it/s]\n"
     ]
    }
   ],
   "source": [
    "# Scale data and build words vector\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "n_dim = 200\n",
    "\n",
    "train_vecs_w2v = np.concatenate([buildWordVector(z, n_dim) for z in tqdm(map(lambda x: x, X_train))])\n",
    "train_vecs_w2v = scale(train_vecs_w2v)\n",
    "\n",
    "test_vecs_w2v = np.concatenate([buildWordVector(z, n_dim) for z in tqdm(map(lambda x: x, X_test))])\n",
    "test_vecs_w2v = scale(test_vecs_w2v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, Activation, Flatten, Bidirectional\n",
    "from keras.utils import to_categorical\n",
    "import keras_metrics\n",
    "\n",
    "# convent labels to categorical classes\n",
    "cy_train = to_categorical(y_train)\n",
    "cy_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21482, 200)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vecs_w2v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "\n",
    "# calculate f score\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 4s - loss: 0.1796 - acc: 0.9394 - precision: 0.9496 - recall: 0.8956 - f1: 0.9192\n",
      "Epoch 2/10\n",
      " - 4s - loss: 0.0913 - acc: 0.9651 - precision: 0.9931 - recall: 0.8221 - f1: 0.8980\n",
      "Epoch 3/10\n",
      " - 3s - loss: 0.0765 - acc: 0.9717 - precision: 0.9968 - recall: 0.7715 - f1: 0.8677\n",
      "Epoch 4/10\n",
      " - 3s - loss: 0.0701 - acc: 0.9725 - precision: 0.9986 - recall: 0.7283 - f1: 0.8395\n",
      "Epoch 5/10\n",
      " - 3s - loss: 0.0616 - acc: 0.9774 - precision: 0.9989 - recall: 0.6980 - f1: 0.8190\n",
      "Epoch 6/10\n",
      " - 3s - loss: 0.0592 - acc: 0.9773 - precision: 0.9992 - recall: 0.6802 - f1: 0.8064\n",
      "Epoch 7/10\n",
      " - 2s - loss: 0.0538 - acc: 0.9798 - precision: 0.9997 - recall: 0.6505 - f1: 0.7848\n",
      "Epoch 8/10\n",
      " - 2s - loss: 0.0526 - acc: 0.9793 - precision: 0.9997 - recall: 0.6410 - f1: 0.7776\n",
      "Epoch 9/10\n",
      " - 3s - loss: 0.0488 - acc: 0.9815 - precision: 0.9996 - recall: 0.6481 - f1: 0.7831\n",
      "Epoch 10/10\n",
      " - 3s - loss: 0.0484 - acc: 0.9813 - precision: 0.9998 - recall: 0.6406 - f1: 0.7775\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 100)               120400    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 120,703\n",
      "Trainable params: 120,703\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "lstm_model.add(Dense(3, activation='sigmoid'))\n",
    "lstm_model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy', \n",
    "                       keras_metrics.precision(),\n",
    "                      keras_metrics.recall(),\n",
    "                      f1])\n",
    "\n",
    "lstm_his = lstm_model.fit(train_vecs_w2v.reshape((train_vecs_w2v.shape[0],1,200)), cy_train, epochs=10, batch_size=32, verbose=2)\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM model acuracy: 97.95860504903524\n"
     ]
    }
   ],
   "source": [
    "score = lstm_model.evaluate(test_vecs_w2v.reshape((test_vecs_w2v.shape[0], 1, test_vecs_w2v.shape[1])), cy_test, batch_size=128, verbose=2)\n",
    "print('LSTM model acuracy: {}'.format(score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAFbNJREFUeJzt3X+QXeV93/H39967u1pphXCtFXEkhLAlN9HgxDhb8I82ZgqeAm6grT0diN04qYvaxthOwzTFTUs7zl9pmbShJnYZ4zhNYyjGHkdTExOPTUvrBIoA1zZQwgZjS9hG4qcl9GN/3G//OHd37652tXe1V7raZ9+vmTP3PM959tzvPdJ+zrnn3HM3MhNJUllqvS5AktR9hrskFchwl6QCGe6SVCDDXZIKZLhLUoEMd0kqkOEuSQUy3CWpQI1ePfHGjRtz27ZtvXp6SVqRHn744eczc3ixcT0L923btrFnz55ePb0krUgR8b1OxnlaRpIKtGi4R8RnImJ/RHxngeUREbdExGhEfCsi3tL9MiVJS9HJkftngctPsPwKYEdr2gV8cvllSZKWY9Fwz8z7gRdPMORq4L9k5QHg7Ih4XbcKlCQtXTfOuW8G9ra197X6jhMRuyJiT0TsOXDgQBeeWpI0n9N6QTUzb8vMkcwcGR5e9JM8kqST1I1wfxY4t629pdUnSeqRbnzOfTdwfUTcCVwMvJKZP+zCeiUtoNlMJprJZDOZaDZbjzn9ODHZZKKZzPwZzSACAoiI1uP0kpn5mL28mmP6Z4mZ8e3ron18cNzyBCYnk8mcqfe4KZOJyaSZ1WuYeo3TrzVzeh0L/vx8P9dsMtmEyWZz9kacetHTW2j+RdG2ZHb/AuPnrHe+p/z5HcNcsHnDguO6YdFwj4g7gEuAjRGxD/g3QB9AZn4KuAe4EhgFDgO/cqqKVVkyk2MTzdY0ybHxJmOTTY6Nt9oTTcbalk/Pjx+/bKo9NtHkRH8VeOFfu4UXxgl+aqHf40ymQ2qy2WRishW6be25gdw+7rjQbusfbzbxTx+fnKl/r15vv7PW9PU+3DPz2kWWJ/ChrlUkoDoyOzoxyeGxSY6MTXJkvHo8PDbJ0fGqfbjVP94KtMwkE5KkmTMBQ2tZe19WnVVf2/hsLZs7Hlo/N9/41pjxyfZwnhPIrVBuXz422Vzo5XesFrCmr05/o8ZAo0ZfvUZtgcTNE8T+Qr/sywmBei1o1IJ6a2rUg0atNt030FdjbVt76rGvXpvVrh5rNOoz7cac9qxxbc9Xi5j+95x6PUlOv66qPfPvTtvyqZeec/um/49MLZ9pz/dcM9ujqq3Wvl1ips72ZdNjYmb7zZ0atamfq1GrMeuxHkG93j6mWmcnsu0fvf3fPxcaM6t/zrqYf12NDmtZjp59/cBK12wmB49NzAreI+MTHBlrcnhsoq1vJpAPt48dm+Tw+CRHp8dMcHR85mePji8/+BYz9da5FnHc2/Faa77WGhRArRYLjg9iOmAH+mr012sMNOqsW9dgoFGjv1GvljWq/vaxs9qt5QMLLq+31le1G3VvslZ3tZ9WWfgMy6kP5+Uy3BcxPtnkey8cZnT/If7ywCFG989MR8YnO15PBKztqzPY32Cwv8bg1HxfjeH1Awz2rWWwv85gX521/XXWtB4H2+f76m1jGgz21VnTXwVpEERtdlhPHcHODeupYJZULsO95ej45HHhPbr/EM+88CrjkzPvp163YQ3bNw1xzUXnsvnswSpk+2sM9jUY7J8vhKtwHmjUDFRJp82qC/dXjoxXR+H7D/HU/oNViB84xL6XjkyfE6sFnPfadbxheIjLdp7D9uEhtm8a4g2bhhgaWHWbTNIKVGRSZSYHDh6bDu7R/Yd46rlq/sDBY9Pj+hs1Xr9xHT+75Wze85Yt7Ni0nu2bhti2cS0DjXoPX4EkLc+KDvdmM9n30hFGDxw87nTKj49OTI9bP9DgDZuGeOcbh9m+aYgdm6oj8S2vWUv9NFy1lqTTbcWF+//8iwN84eF9jO4/xNPPH5r1qZKNQ/1s3zTEVW/+ydaplPXsOGeITesHPN8taVVZceG+98XDPPy9l9i+aYi3v+G1bG8dhW/fNMTZa/t7XZ4knRFWXLi/7+KtvP+t5/W6DEk6o624O0A8vSJJi1tx4S5JWpzhLkkFMtwlqUCGuyQVyHCXpAIZ7pJUIMNdkgpkuEtSgQx3SSqQ4S5JBTLcJalAhrskFchwl6QCGe6SVCDDXZIKZLhLUoEMd0kqkOEuSQUy3CWpQIa7JBXIcJekAhnuklQgw12SCtRRuEfE5RHxZESMRsSN8yzfGhH3RcSjEfGtiLiy+6VKkjq1aLhHRB24FbgC2AlcGxE75wz7V8BdmXkhcA3we90uVJLUuU6O3C8CRjPz6cwcA+4Erp4zJoGzWvMbgB90r0RJ0lI1OhizGdjb1t4HXDxnzL8F/jQiPgysAy7rSnWSpJPSrQuq1wKfzcwtwJXAH0bEceuOiF0RsSci9hw4cKBLTy1JmquTcH8WOLetvaXV1+6DwF0AmfnnwBpg49wVZeZtmTmSmSPDw8MnV7EkaVGdhPtDwI6IOD8i+qkumO6eM+b7wKUAEfHTVOHuobkk9cii4Z6ZE8D1wL3AE1SfinksIj4eEVe1ht0AXBcR/xe4A/jlzMxTVbQk6cQ6uaBKZt4D3DOn76a2+ceBd3S3NEnSyfIOVUkqkOEuSQUy3CWpQIa7JBXIcJekAhnuklQgw12SCmS4S1KBDHdJKpDhLkkFMtwlqUCGuyQVyHCXpAIZ7pJUIMNdkgpkuEtSgQx3SSqQ4S5JBTLcJalAhrskFchwl6QCGe6SVCDDXZIKZLhLUoEMd0kqkOEuSQUy3CWpQIa7JBXIcJekAhnuklQgw12SCmS4S1KBDHdJKlBH4R4Rl0fEkxExGhE3LjDm70fE4xHxWER8rrtlSpKWorHYgIioA7cC7wL2AQ9FxO7MfLxtzA7gY8A7MvOliNh0qgqWJC2ukyP3i4DRzHw6M8eAO4Gr54y5Drg1M18CyMz93S1TkrQUnYT7ZmBvW3tfq6/dG4E3RsQ3IuKBiLi8WwVKkpZu0dMyS1jPDuASYAtwf0S8KTNfbh8UEbuAXQBbt27t0lNLkubq5Mj9WeDctvaWVl+7fcDuzBzPzO8Cf0EV9rNk5m2ZOZKZI8PDwydbsyRpEZ2E+0PAjog4PyL6gWuA3XPGfInqqJ2I2Eh1mubpLtYpSVqCRcM9MyeA64F7gSeAuzLzsYj4eERc1Rp2L/BCRDwO3Af888x84VQVLUk6scjMnjzxyMhI7tmzpyfPLUkrVUQ8nJkji43zDlVJKpDhLkkFMtwlqUCGuyQVyHCXpAIZ7pJUIMNdkgpkuEtSgQx3SSqQ4S5JBTLcJalAhrskFchwl6QCGe6SVCDDXZIKZLhLUoEMd0kqkOEuSQUy3CWpQIa7JBXIcJekAhnuklQgw12SCmS4S1KBDHdJKpDhLkkFMtwlqUCGuyQVyHCXpAIZ7pJUIMNdkgpkuEtSgQx3SSqQ4S5JBeoo3CPi8oh4MiJGI+LGE4x7T0RkRIx0r0RJ0lItGu4RUQduBa4AdgLXRsTOecatBz4KPNjtIiVJS9PJkftFwGhmPp2ZY8CdwNXzjPst4LeBo12sT5J0EjoJ983A3rb2vlbftIh4C3BuZn75RCuKiF0RsSci9hw4cGDJxUqSOrPsC6oRUQN+B7hhsbGZeVtmjmTmyPDw8HKfWpK0gE7C/Vng3Lb2llbflPXABcD/iIhngLcCu72oKkm900m4PwTsiIjzI6IfuAbYPbUwM1/JzI2ZuS0ztwEPAFdl5p5TUrEkaVGLhntmTgDXA/cCTwB3ZeZjEfHxiLjqVBcoSVq6RieDMvMe4J45fTctMPaS5ZclSVoO71CVpAIZ7pJUIMNdkgpkuEtSgQx3SSqQ4S5JBTLcJalAhrskFchwl6QCGe6SVCDDXZIKZLhLUoEMd0kqkOEuSQUy3CWpQIa7JBXIcJekAhnuklQgw12SCmS4S1KBDHdJKpDhLkkFMtwlqUCGuyQVyHCXpAIZ7pJUIMNdkgpkuEtSgQx3SSqQ4S5JBTLcJalAhrskFchwl6QCdRTuEXF5RDwZEaMRceM8y389Ih6PiG9FxNci4rzulypJ6tSi4R4RdeBW4ApgJ3BtROycM+xRYCQzfwa4G/h33S5UktS5To7cLwJGM/PpzBwD7gSubh+Qmfdl5uFW8wFgS3fLlCQtRSfhvhnY29be1+pbyAeBP1lOUZKk5Wl0c2UR8X5gBHjnAst3AbsAtm7d2s2nliS16eTI/Vng3Lb2llbfLBFxGfCbwFWZeWy+FWXmbZk5kpkjw8PDJ1OvJKkDnYT7Q8COiDg/IvqBa4Dd7QMi4kLgP1MF+/7ulylJWopFwz0zJ4DrgXuBJ4C7MvOxiPh4RFzVGvbvgSHg8xHxzYjYvcDqlm/v/4Ev/Sq8ctybB0lSS0fn3DPzHuCeOX03tc1f1uW6Fvbcd+Dbn4fvfBHe9iH4678GA+tP29NL0kqw8u5QHfmHcP1D8FPvhv91M9xyITx0O0xO9LoySTpjrLxwB3jNNnjv7XDd12HjG+HLvw6ffBs8+SeQ2evqJKnnVma4T9n8c/DLX4ZrPleF+h3XwB/8Avzg0V5XJkk9tbLDHSCiOkXzq38OV94M+5+A2y6BL1wHL3+/19VJUk+s/HCfUu+Di66DjzwKf+MGeGI3/KcR+OpNcOTlXlcnSadVOeE+Zc1ZcOlN8OGH4YL3wDduqS66PvApmBjrdXWSdFqUF+5TNmyBv/tJ+Mf3w0+8Cb7yL+D3LobH/9iLrpKKV264T3ndz8Av/TG8726oD8BdvwSf+VvVzVCSVKjywx2qi6473gX/5H/DL9wCLz0Dt78L7voAvPh0r6uTpK5bHeE+pd6An/sAfPgRuORj8NRX4RMXwVc+Bodf7HV1ktQ1qyvcpwwMwSU3wkcegTf/Ijz4KfjdN1cXX8eP9ro6SVq21RnuU9b/BFx1C/zTP4OtF8NX/zV84q/Bt++GZrPX1UnSSVvd4T5l00/D+z5fXXgd3ABf+CB8+lJ45hu9rkySTorh3u71l8Cu++HvfAoOPQefvRLu+EV4/qleVyZJS2K4z1WrwZuvrW6CuvQm+O79cOvF8OUb4NCBXlcnSR0x3BfSN1h9jcFHHq2+ZnjP71d3ut5/M4wd7nV1knRChvtihobh3TfDhx6E178Tvv5b8IkR+ObnvOgq6YwV2aNb8UdGRnLPnj09ee5l+d6fwb2/CT94BNZuhA2bYegcGNoE6zbNzA+d05qGYeCs6kYqSVqmiHg4M0cWG9fRn9lTm/PeDv/oa/D4l2D0a/Dq/uri64++DYf2Q04e/zONNTOBv25TW/i3P7bm+wZP/2uSVBzD/WTUanDB36umds0mHHmpCvtDz1VhPxX+h1qPLz0Dex+Ewy8A87xrGjgL1g0vHP7TO4nh6muOJWkehns31Wqw7rXVdM7OE4+dHIdXn2+F//7ZO4Sp6bnH4C/vg2OvzL+Owb9SBf3g2dURf9/a1jQ489g/t6+9PQj962Yva6ypXoekFc1w75V6H5z1umpazPjROTuBOTuEYz+GYwfh4HMwfhjGj7SmV6F5En84vDE3+BfaccxZ3j8EA+tnprlt32lIp43hvhL0rYGzt1bTUk2OV4E/dvj44B8/0rbsSNvyV2fGjbWNO/oKHPzhzLixw9XY7PBTQ/WBtrAfqk5BTe8AWo/962e35+vrX199CZykBfkbUrp6H9Q3wJoNp2b9ma0dyKvVjuDYQTh2aObdxNih2X2z2gfh0I/ghadm+iaOdPa8jcG2sG/tKAbWV+8m6v1Qq0Ot0TbVF+ibpx31xccsut6+6hRXY6B6Z1Nr+IkpnVaGu5YnAhr91TT4muWvb3ICxg7O3gEc127bebT3/Xhf1W5OVqejpqc57fk+0XSqRa11umtNK/RbU9+aqn9qJzCrf575xpoTjGutp319tfrpf606IxjuOrPUG9VOohs7ioVkVqeSTrQDmO6b7GBMa4fR3p4cg4ljMHG0umYy0ZrGj7T6W4/jR6r+oy/DwR/NP67T017ziXq1Y5l3ihMs6/LyWqN6R1Xvaz225hsDx/d1c77Wt2o/IGC4a/WJaJ16qQMDva7mxDKrncXUTqDTncXUuMljMzuz6Wlue+602PIO19GchBxv7UjHq9N3k2OtaZ75k7n434n2HUu03slEANGFeU7uZ9/5G/Cm93bvNc7DcJfOZBGto9A+4KxeV3NqNad2AguE/3LmJ45V89kEstr5wBLmWeL4ReZP5TvTFsNd0pmhVoPaQHWqRsu2Ok9GSVLhDHdJKpDhLkkFMtwlqUCGuyQVqKNwj4jLI+LJiBiNiBvnWT4QEf+ttfzBiNjW7UIlSZ1bNNwjog7cClwB7ASujYi532f7QeClzNwO/Afgt7tdqCSpc50cuV8EjGbm05k5BtwJXD1nzNXAH7Tm7wYujfBbkiSpVzq5iWkzsLetvQ+4eKExmTkREa8ArwWebx8UEbuAXa3moYh48mSKBjbOXfcq5/aYze0xw20xWwnb47xOBp3WO1Qz8zbgtuWuJyL2dPIHYlcLt8dsbo8ZbovZVtP26OS0zLPAuW3tLa2+ecdERAPYALzQjQIlSUvXSbg/BOyIiPMjoh+4Btg9Z8xu4AOt+fcCX8+c/rYcSdJptuhpmdY59OuBe4E68JnMfCwiPg7syczdwO3AH0bEKPAi1Q7gVFr2qZ3CuD1mc3vMcFvMtmq2R3iALUnl8Q5VSSrQigv3xe6WXS0i4tyIuC8iHo+IxyLio72u6UwQEfWIeDQi/nuva+m1iDg7Iu6OiP8XEU9ExNt6XVOvRMQ/a/2efCci7oiINb2u6VRbUeHe4d2yq8UEcENm7gTeCnxoFW+Ldh8Fnuh1EWeI3wW+kpk/Bfwsq3S7RMRm4CPASGZeQHXt8FRfF+y5FRXudHa37KqQmT/MzEda8wepfnE397aq3oqILcC7gU/3upZei4gNwM9TfdiBzBzLzJd7W1VPNYDB1ke11wI/6HE9p9xKC/f57pZd1YEG0PqitguBB3tbSc/9R+A3gGavCzkDnA8cAH6/dZrq0xGxrtdF9UJmPgvcDHwf+CHwSmb+aW+rOvVWWrhrjogYAr4A/Fpm/rjX9fRKRPxtYH9mPtzrWs4QDeAtwCcz80LgVWBVXqOKiNdQvcM/H/hJYF1EvL+3VZ16Ky3cO7lbdtWIiD6qYP+jzPxir+vpsXcAV0XEM1Sn6/5mRPzX3pbUU/uAfZk59W7ubqqwX40uA76bmQcycxz4IvD2Htd0yq20cO/kbtlVofWtm7cDT2Tm7/S6nl7LzI9l5pbM3Eb1/+LrmVn80dlCMvNHwN6I+KutrkuBx3tYUi99H3hrRKxt/d5cyiq4uHxavzhsuRa6W7bHZfXKO4B/AHw7Ir7Z6vuXmXlPD2vSmeXDwB+1DoSeBn6lx/X0RGY+GBF3A49QfcrsUVbBnareoSpJBVppp2UkSR0w3CWpQIa7JBXIcJekAhnuklQgw12SCmS4S1KBDHdJKtD/Byp1WSAw5MDbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(lstm_his.history['acc'])\n",
    "plt.plot(lstm_his.history['loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the model to the disk\n",
    "# use should install HDF5 or h5py to save the model\n",
    "# see: https://keras.io/getting-started/faq/#how-can-i-save-a-keras-model\n",
    "\n",
    "# lstm_model.save('lstm_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 7s - loss: 0.1471 - acc: 0.9504 - precision: 0.9683 - recall: 0.8446 - f1: 0.8985\n",
      "Epoch 2/10\n",
      " - 5s - loss: 0.0774 - acc: 0.9710 - precision: 0.9970 - recall: 0.7328 - f1: 0.8418\n",
      "Epoch 3/10\n",
      " - 4s - loss: 0.0661 - acc: 0.9756 - precision: 0.9983 - recall: 0.6695 - f1: 0.7982\n",
      "Epoch 4/10\n",
      " - 4s - loss: 0.0580 - acc: 0.9776 - precision: 0.9993 - recall: 0.6362 - f1: 0.7736\n",
      "Epoch 5/10\n",
      " - 4s - loss: 0.0528 - acc: 0.9798 - precision: 0.9994 - recall: 0.6208 - f1: 0.7623\n",
      "Epoch 6/10\n",
      " - 4s - loss: 0.0462 - acc: 0.9820 - precision: 0.9999 - recall: 0.6099 - f1: 0.7537\n",
      "Epoch 7/10\n",
      " - 4s - loss: 0.0450 - acc: 0.9825 - precision: 0.9997 - recall: 0.6082 - f1: 0.7525\n",
      "Epoch 8/10\n",
      " - 4s - loss: 0.0399 - acc: 0.9847 - precision: 0.9999 - recall: 0.6217 - f1: 0.7633\n",
      "Epoch 9/10\n",
      " - 4s - loss: 0.0384 - acc: 0.9855 - precision: 0.9998 - recall: 0.6181 - f1: 0.7600\n",
      "Epoch 10/10\n",
      " - 5s - loss: 0.0356 - acc: 0.9857 - precision: 0.9999 - recall: 0.6270 - f1: 0.7675\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_2 (Bidirection (None, 200)               240800    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 603       \n",
      "=================================================================\n",
      "Total params: 241,403\n",
      "Trainable params: 241,403\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(100, dropout=0.2, recurrent_dropout=0.2)))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy',\n",
    "                      keras_metrics.precision(),\n",
    "                      keras_metrics.recall(),\n",
    "                      f1])\n",
    "history = model.fit(train_vecs_w2v.reshape((train_vecs_w2v.shape[0],1,200)),\n",
    "                    cy_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    verbose=2)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bidirectional model acuracy: 98.3082884426728\n"
     ]
    }
   ],
   "source": [
    "# The accuracy of the model\n",
    "score = model.evaluate(test_vecs_w2v.reshape((test_vecs_w2v.shape[0], 1, test_vecs_w2v.shape[1])), cy_test, batch_size=128, verbose=2)\n",
    "print('Bidirectional model acuracy: {}'.format(score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm_model.save('bilstm_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the model\n",
    "# from keras.models import load_model\n",
    "# loaded_model = load_model(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
